{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM2 Interpretability from CIF\n",
    "This notebook extracts sequences and DSSP labels from CIF files, embeds with ESM2, and learns biological directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, esm, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from Bio.PDB import MMCIFParser, PPBuilder, calc_dihedral, NeighborSearch\n",
    "from Bio.PDB.DSSP import DSSP\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_dir = './pdbs'\n",
    "\n",
    "all_X, all_ss, all_rsa = [], [], []\n",
    "all_phi, all_psi, all_bfactors = [], [], []\n",
    "all_contacts, all_hydrophobicity, all_charge = [], [], []\n",
    "all_sequences, all_coords = [], []\n",
    "\n",
    "# Amino acid properties\n",
    "aa_hydrophobicity = {\n",
    "    'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "    'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "aa_charge = {\n",
    "    'A': 0, 'R': 1, 'N': 0, 'D': -1, 'C': 0, 'Q': 0, 'E': -1, \n",
    "    'G': 0, 'H': 0.1, 'I': 0, 'L': 0, 'K': 1, 'M': 0, 'F': 0, \n",
    "    'P': 0, 'S': 0, 'T': 0, 'W': 0, 'Y': 0, 'V': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model.eval()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "parser = MMCIFParser(QUIET=True)\n",
    "ppb = PPBuilder()\n",
    "\n",
    "def calculate_phi_psi(residues):\n",
    "    \"\"\"Calculate phi and psi angles for a chain of residues\"\"\"\n",
    "    phi_angles, psi_angles = [], []\n",
    "    for i, residue in enumerate(residues):\n",
    "        try:\n",
    "            if i > 0 and i < len(residues) - 1:\n",
    "                # Phi angle: C(i-1) - N(i) - CA(i) - C(i)\n",
    "                phi = calc_dihedral(residues[i-1]['C'].get_vector(),\n",
    "                                  residue['N'].get_vector(),\n",
    "                                  residue['CA'].get_vector(),\n",
    "                                  residue['C'].get_vector())\n",
    "                # Psi angle: N(i) - CA(i) - C(i) - N(i+1)\n",
    "                psi = calc_dihedral(residue['N'].get_vector(),\n",
    "                                  residue['CA'].get_vector(),\n",
    "                                  residue['C'].get_vector(),\n",
    "                                  residues[i+1]['N'].get_vector())\n",
    "                phi_angles.append(phi)\n",
    "                psi_angles.append(psi)\n",
    "            else:\n",
    "                phi_angles.append(0.0)\n",
    "                psi_angles.append(0.0)\n",
    "        except:\n",
    "            phi_angles.append(0.0)\n",
    "            psi_angles.append(0.0)\n",
    "    return phi_angles, psi_angles\n",
    "\n",
    "def calculate_contacts(residues, cutoff=8.0):\n",
    "    \"\"\"Calculate contact map for residues\"\"\"\n",
    "    coords = []\n",
    "    for res in residues:\n",
    "        try:\n",
    "            coords.append(res['CA'].get_coord())\n",
    "        except:\n",
    "            coords.append(np.array([0, 0, 0]))\n",
    "    \n",
    "    coords = np.array(coords)\n",
    "    distances = squareform(pdist(coords))\n",
    "    contacts = (distances < cutoff).astype(float)\n",
    "    \n",
    "    # Return contact density for each residue\n",
    "    contact_density = np.sum(contacts, axis=1) / len(contacts)\n",
    "    return contact_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84450b56",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 CIF files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CIF files:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CIF files: 100%|██████████| 200/200 [1:55:33<00:00, 34.67s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1915 protein chains\n",
      "Total residues: 303804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cif_files = [f for f in os.listdir(cif_dir) if f.endswith('.cif')]\n",
    "print(f\"Found {len(cif_files)} CIF files to process\")\n",
    "\n",
    "for cif in tqdm(cif_files, desc=\"Processing CIF files\"):\n",
    "    path = os.path.join(cif_dir, cif)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Warning: {cif} not found at {path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        struct = parser.get_structure('x', path)\n",
    "        dssp = DSSP(struct[0], path)\n",
    "        \n",
    "        for model0 in struct:\n",
    "            for chain in model0:\n",
    "                peptides = ppb.build_peptides(chain)\n",
    "                residues = list(chain.get_residues())\n",
    "                \n",
    "                for pep in peptides:\n",
    "                    seq = str(pep.get_sequence())\n",
    "                    if len(seq) < 10:  # Skip very short sequences\n",
    "                        continue\n",
    "                        \n",
    "                    data = [('p', seq)]\n",
    "                    _, _, toks = batch_converter(data)\n",
    "                    with torch.no_grad(): \n",
    "                        out = model(toks, repr_layers=[33])\n",
    "                    reps = out['representations'][33][0, 1:len(seq)+1].numpy()\n",
    "                    \n",
    "                    # Structural features from DSSP\n",
    "                    ss, rsa, bfac = [], [], []\n",
    "                    valid_indices = []\n",
    "                    \n",
    "                    for i, key in enumerate(dssp.keys()):\n",
    "                        if i >= len(seq): break\n",
    "                        try:\n",
    "                            ss.append(dssp[key][2])\n",
    "                            rsa.append(dssp[key][3])\n",
    "                            # B-factor (temperature factor)\n",
    "                            bfac.append(residues[i]['CA'].get_bfactor() if i < len(residues) else 50.0)\n",
    "                            valid_indices.append(i)\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if len(valid_indices) < len(seq) * 0.8:  # Skip if too many missing values\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate dihedral angles\n",
    "                    phi_angles, psi_angles = calculate_phi_psi(residues[:len(seq)])\n",
    "                    \n",
    "                    # Calculate contact density\n",
    "                    contacts = calculate_contacts(residues[:len(seq)])\n",
    "                    \n",
    "                    # Physicochemical properties\n",
    "                    hydrophob = [aa_hydrophobicity.get(aa, 0) for aa in seq]\n",
    "                    charges = [aa_charge.get(aa, 0) for aa in seq]\n",
    "                    \n",
    "                    # Store all features (only for valid residues)\n",
    "                    all_X.append(reps[:len(valid_indices)])\n",
    "                    all_ss.append(np.array(ss))\n",
    "                    all_rsa.append(np.array(rsa))\n",
    "                    all_phi.append(np.array(phi_angles[:len(valid_indices)]))\n",
    "                    all_psi.append(np.array(psi_angles[:len(valid_indices)]))\n",
    "                    all_bfactors.append(np.array(bfac))\n",
    "                    all_contacts.append(contacts[:len(valid_indices)])\n",
    "                    all_hydrophobicity.append(np.array(hydrophob[:len(valid_indices)]))\n",
    "                    all_charge.append(np.array(charges[:len(valid_indices)]))\n",
    "                    all_sequences.append(seq[:len(valid_indices)])\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cif}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(all_X)} protein chains\")\n",
    "print(f\"Total residues: {sum(len(x) for x in all_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Y_rsa range: [0.000, 1.000]\n",
      "Feature matrix shape: (303804, 1280)\n",
      "Unique secondary structures: ['-' 'B' 'E' 'G' 'H' 'I' 'P' 'S' 'T']\n",
      "RSA range: [0.000, 1.000]\n",
      "Contact density range: [0.002, 1.000]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate(all_X)\n",
    "Y_ss = np.concatenate(all_ss)\n",
    "Y_rsa = np.concatenate(all_rsa)\n",
    "\n",
    "Y_rsa_fixed = []\n",
    "for val in Y_rsa:\n",
    "    try:\n",
    "        Y_rsa_fixed.append(float(val))\n",
    "    except ValueError:\n",
    "        Y_rsa_fixed.append(0.0)  # Default for non-numeric\n",
    "Y_rsa = np.array(Y_rsa_fixed)\n",
    "print(f\"Fixed Y_rsa range: [{Y_rsa.min():.3f}, {Y_rsa.max():.3f}]\")\n",
    "\n",
    "Y_phi = np.concatenate(all_phi)\n",
    "Y_psi = np.concatenate(all_psi)\n",
    "Y_bfactors = np.concatenate(all_bfactors)\n",
    "Y_contacts = np.concatenate(all_contacts)\n",
    "Y_hydrophobicity = np.concatenate(all_hydrophobicity)\n",
    "Y_charge = np.concatenate(all_charge)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Unique secondary structures: {np.unique(Y_ss)}\")\n",
    "print(f\"RSA range: [{Y_rsa.min():.3f}, {Y_rsa.max():.3f}]\")\n",
    "print(f\"Contact density range: [{Y_contacts.min():.3f}, {Y_contacts.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962358d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['-', 'B', 'E', 'G', 'H', 'I', 'P', 'S', 'T'], dtype='<U1'), array([ 62021,   3289,  46170,  11962, 108724,   2240,   6113,  29643,\n",
      "        33642]))\n",
      "Fixed Y_rsa range: [0.000, 1.000]\n",
      "[1.         0.20710059 0.4084507  0.43661972 0.48969072 0.76209677\n",
      " 0.17924528 0.48591549 0.20121951 0.25352113]\n"
     ]
    }
   ],
   "source": [
    "# save processed data to avoid re-running the long processing (115 minutes)\n",
    "\n",
    "np.savez('processed_data.npz', \n",
    "         X=X, Y_ss=Y_ss, Y_rsa=Y_rsa, Y_phi=Y_phi, Y_psi=Y_psi,\n",
    "         Y_bfactors=Y_bfactors, Y_contacts=Y_contacts, \n",
    "         Y_hydrophobicity=Y_hydrophobicity, Y_charge=Y_charge)\n",
    "print(\"Data saved to processed_data.npz\")\n",
    "\n",
    "# run this to load it\n",
    "\n",
    "# with np.load('processed_data.npz') as data:\n",
    "#     X = data['X']\n",
    "#     Y_ss = data['Y_ss']\n",
    "#     Y_rsa = data['Y_rsa']\n",
    "#     Y_phi = data['Y_phi']\n",
    "#     Y_psi = data['Y_psi']\n",
    "#     Y_bfactors = data['Y_bfactors']\n",
    "#     Y_contacts = data['Y_contacts']\n",
    "#     Y_hydrophobicity = data['Y_hydrophobicity']\n",
    "#     Y_charge = data['Y_charge']\n",
    "\n",
    "# print(np.unique(Y_ss, return_counts=True))\n",
    "\n",
    "# Y_rsa_fixed = []\n",
    "# for val in Y_rsa:\n",
    "#     try:\n",
    "#         Y_rsa_fixed.append(float(val))\n",
    "#     except ValueError:\n",
    "#         Y_rsa_fixed.append(0.0)  # Default for non-numeric\n",
    "# Y_rsa = np.array(Y_rsa_fixed)\n",
    "# print(f\"Fixed Y_rsa range: [{Y_rsa.min():.3f}, {Y_rsa.max():.3f}]\")\n",
    "# print(Y_rsa[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180361bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary_structure: 0.891\n",
      "rsa            : 0.356\n",
      "bfactor        : 0.282\n",
      "contacts       : 0.778\n",
      "hydrophobicity : 0.965\n",
      "charge         : 0.963\n"
     ]
    }
   ],
   "source": [
    "probes = {}\n",
    "results = {}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# 1. Secondary structure (multiclass linear probe)\n",
    "\n",
    "ss_mask = np.array([s in [\"H\",\"E\",\"C\"] for s in Y_ss])\n",
    "X_ss = X[ss_mask]\n",
    "Y_ss_filt = Y_ss[ss_mask]\n",
    "\n",
    "clf_ss = LogisticRegression(\n",
    "    max_iter=100,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "acc = []\n",
    "for train, test in kf.split(X_ss):\n",
    "    clf_ss.fit(X_ss[train], Y_ss_filt[train])\n",
    "    acc.append(accuracy_score(Y_ss_filt[test], clf_ss.predict(X_ss[test])))\n",
    "\n",
    "results[\"secondary_structure\"] = np.mean(acc)\n",
    "joblib.dump(clf_ss, \"./models/ss_probe.pkl\")\n",
    "probes[\"ss\"] = clf_ss\n",
    "\n",
    "# 2. Relative solvent accessibility (regression)\n",
    "\n",
    "mask = np.isfinite(Y_rsa)\n",
    "X_rsa = X[mask]\n",
    "Y_rsa2 = Y_rsa[mask]\n",
    "\n",
    "rsa_probe = Ridge(alpha=1.0)\n",
    "r2 = []\n",
    "\n",
    "for train, test in kf.split(X_rsa):\n",
    "    rsa_probe.fit(X_rsa[train], Y_rsa2[train])\n",
    "    r2.append(r2_score(Y_rsa2[test], rsa_probe.predict(X_rsa[test])))\n",
    "\n",
    "results[\"rsa\"] = np.mean(r2)\n",
    "joblib.dump(rsa_probe, \"./models/rsa_probe.pkl\")\n",
    "probes[\"rsa\"] = rsa_probe\n",
    "\n",
    "# 3. B-factor (flexibility)\n",
    "\n",
    "mask = np.isfinite(Y_bfactors)\n",
    "bf_probe = Ridge(alpha=1.0)\n",
    "\n",
    "r2 = []\n",
    "for train, test in kf.split(X[mask]):\n",
    "    bf_probe.fit(X[mask][train], Y_bfactors[mask][train])\n",
    "    r2.append(r2_score(Y_bfactors[mask][test], bf_probe.predict(X[mask][test])))\n",
    "\n",
    "results[\"bfactor\"] = np.mean(r2)\n",
    "joblib.dump(bf_probe, \"./models/bfactor_probe.pkl\")\n",
    "probes[\"bfactor\"] = bf_probe\n",
    "\n",
    "# 4. Contact density\n",
    "\n",
    "cd_probe = Ridge(alpha=1.0)\n",
    "r2 = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    cd_probe.fit(X[train], Y_contacts[train])\n",
    "    r2.append(r2_score(Y_contacts[test], cd_probe.predict(X[test])))\n",
    "\n",
    "results[\"contacts\"] = np.mean(r2)\n",
    "joblib.dump(cd_probe, \"./models/contacts_probe.pkl\")\n",
    "probes[\"contacts\"] = cd_probe\n",
    "\n",
    "# 5. Hydrophobicity\n",
    "\n",
    "hydro_probe = Ridge(alpha=1.0)\n",
    "r2 = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    hydro_probe.fit(X[train], Y_hydrophobicity[train])\n",
    "    r2.append(r2_score(Y_hydrophobicity[test], hydro_probe.predict(X[test])))\n",
    "\n",
    "results[\"hydrophobicity\"] = np.mean(r2)\n",
    "joblib.dump(hydro_probe, \"./models/hydro_probe.pkl\")\n",
    "probes[\"hydro\"] = hydro_probe\n",
    "\n",
    "# 6. Charge\n",
    "\n",
    "charge_probe = Ridge(alpha=1.0)\n",
    "r2 = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    charge_probe.fit(X[train], Y_charge[train])\n",
    "    r2.append(r2_score(Y_charge[test], charge_probe.predict(X[test])))\n",
    "\n",
    "results[\"charge\"] = np.mean(r2)\n",
    "joblib.dump(charge_probe, \"./models/charge_probe.pkl\")\n",
    "probes[\"charge\"] = charge_probe\n",
    "\n",
    "for k,v in results.items():\n",
    "    print(f\"{k:15s}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2bd8d8",
   "metadata": {},
   "source": [
    "Charge, Hydrophobicity and secondary structure: Almost perfectly encoded\n",
    "\n",
    "Contracts: Strong \n",
    "\n",
    "RSA and B-Factor: weak (dynamics not purely encoded in sequenec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09745ca3",
   "metadata": {},
   "source": [
    "## The 20 dimensions that mostly encode biological property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INTERPRETABLE ESM2 DIRECTIONS ===\n",
      "[18, 44, 53, 64, 102, 105, 119, 143, 153, 157, 167, 177, 188, 197, 198, 202, 231, 237, 254, 295, 317, 318, 326, 330, 343, 372, 393, 405, 411, 423, 441, 445, 454, 521, 546, 547, 568, 579, 581, 616, 628, 630, 661, 690, 737, 742, 754, 777, 800, 805, 809, 810, 826, 834, 839, 873, 876, 881, 883, 887, 892, 904, 908, 910, 923, 926, 940, 942, 952, 955, 967, 987, 991, 994, 1000, 1038, 1054, 1075, 1092, 1097, 1112, 1118, 1127, 1139, 1147, 1158, 1161, 1206, 1210, 1211, 1212, 1215, 1216, 1239, 1243, 1252]\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20\n",
    "\n",
    "# Secondary structure\n",
    "W_ss = probes[\"ss\"].coef_[0]\n",
    "top = np.argsort(np.abs(W_ss))[-n_dims:]\n",
    "# print(\"Secondary structure (H/E/C):\", top)\n",
    "\n",
    "all_dims = set()\n",
    "\n",
    "# Regression probes\n",
    "def top_dims(probe, name):\n",
    "    w = probe.coef_\n",
    "    top = np.argsort(np.abs(w).ravel())[-n_dims:]\n",
    "    for d in top:\n",
    "        all_dims.add(int(d))\n",
    "\n",
    "    print(f\"{name:15s}: {top}\")\n",
    "\n",
    "top_dims(probes[\"rsa\"], \"Surface (RSA)\")\n",
    "top_dims(probes[\"bfactor\"], \"Flexibility\")\n",
    "top_dims(probes[\"contacts\"], \"Contacts\")\n",
    "top_dims(probes[\"hydro\"], \"Hydrophobicity\")\n",
    "top_dims(probes[\"charge\"], \"Charge\")\n",
    "\n",
    "print(\"All occuring dimensions:\")\n",
    "print(sorted(all_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dimension overlap and orthogonality\n",
    "def analyze_dimension_overlap(dims_dict):\n",
    "    \"\"\"Analyze overlap between different biological property dimensions\"\"\"\n",
    "    properties = list(dims_dict.keys())\n",
    "    overlap_matrix = np.zeros((len(properties), len(properties)))\n",
    "    \n",
    "    for i, prop1 in enumerate(properties):\n",
    "        for j, prop2 in enumerate(properties):\n",
    "            dims1 = set(dims_dict[prop1])\n",
    "            dims2 = set(dims_dict[prop2])\n",
    "            overlap = len(dims1.intersection(dims2)) / len(dims1.union(dims2))\n",
    "            overlap_matrix[i, j] = overlap\n",
    "    \n",
    "    return overlap_matrix, properties\n",
    "\n",
    "dims_dict = {\n",
    "    'Helix': helix_dims,\n",
    "    'Sheet': sheet_dims, \n",
    "    'Surface': surface_dims,\n",
    "    'Flexibility': flexibility_dims,\n",
    "    'Contacts': contact_dims,\n",
    "    'Hydrophobic': hydrophobic_dims,\n",
    "    'Charge': charge_dims\n",
    "}\n",
    "\n",
    "overlap_matrix, properties = analyze_dimension_overlap(dims_dict)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(overlap_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            xticklabels=properties, yticklabels=properties)\n",
    "plt.title('Dimension Overlap Between Biological Properties')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19178982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance analysis\n",
    "def detailed_performance_analysis():\n",
    "    \"\"\"Generate detailed classification reports for each property\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    classifiers = [\n",
    "        (clf_ss, Y_ss, 'Secondary Structure', ss_classes),\n",
    "        (clf_rsa, Y_rsa_bin, 'Surface Accessibility', ['Buried', 'Exposed']),\n",
    "        (clf_bfactor, Y_bfactor_bin, 'Flexibility (B-factor)', ['Low', 'High']),\n",
    "        (clf_contacts, Y_contacts_bin, 'Contact Density', ['Low', 'High']),\n",
    "        (clf_hydrophob, Y_hydrophob_bin, 'Hydrophobicity', ['Hydrophilic', 'Hydrophobic']),\n",
    "        (clf_charge, Y_charge_bin, 'Charge', ['Neutral', 'Charged'])\n",
    "    ]\n",
    "    \n",
    "    for i, (clf, y_true, title, labels) in enumerate(classifiers):\n",
    "        y_pred = clf.predict(X)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Normalize confusion matrix\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        sns.heatmap(cm_norm, annot=True, fmt='.3f', cmap='Blues',\n",
    "                   xticklabels=labels, yticklabels=labels, ax=axes[i])\n",
    "        axes[i].set_title(f'{title}\\nAccuracy: {clf.score(X, y_true):.3f}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed classification reports\n",
    "    for clf, y_true, title, _ in classifiers:\n",
    "        print(f\"\\n=== {title} ===\")\n",
    "        y_pred = clf.predict(X)\n",
    "        print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "detailed_performance_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ebe280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance and biological interpretation\n",
    "def analyze_feature_importance():\n",
    "    \"\"\"Analyze which ESM2 dimensions are most important for each biological property\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    feature_sets = [\n",
    "        (W_ss[list(ss_classes).index('H')] if 'H' in ss_classes else np.zeros(X.shape[1]), 'Alpha Helix', 'red'),\n",
    "        (W_ss[list(ss_classes).index('E')] if 'E' in ss_classes else np.zeros(X.shape[1]), 'Beta Sheet', 'blue'),\n",
    "        (clf_rsa.coef_[0], 'Surface Exposure', 'green'),\n",
    "        (clf_bfactor.coef_[0], 'Flexibility', 'orange'),\n",
    "        (clf_contacts.coef_[0], 'Contact Density', 'purple'),\n",
    "        (clf_hydrophob.coef_[0], 'Hydrophobicity', 'brown'),\n",
    "        (clf_charge.coef_[0], 'Charge', 'pink'),\n",
    "        (np.var(X, axis=0), 'ESM2 Variance', 'gray')\n",
    "    ]\n",
    "    \n",
    "    for i, (weights, title, color) in enumerate(feature_sets):\n",
    "        axes[i].bar(range(len(weights)), np.abs(weights), color=color, alpha=0.7)\n",
    "        axes[i].set_title(f'{title}\\nMax: {np.max(np.abs(weights)):.3f}')\n",
    "        axes[i].set_xlabel('ESM2 Dimension')\n",
    "        axes[i].set_ylabel('Absolute Weight')\n",
    "        \n",
    "        # Highlight top 20 dimensions\n",
    "        top_dims = np.argsort(np.abs(weights))[-20:]\n",
    "        for dim in top_dims:\n",
    "            axes[i].bar(dim, np.abs(weights[dim]), color='black', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramachandran plot analysis using learned directions\n",
    "def ramachandran_analysis():\n",
    "    \"\"\"Analyze how ESM2 representations relate to backbone geometry\"\"\"\n",
    "    \n",
    "    # Convert angles to degrees\n",
    "    phi_deg = np.degrees(Y_phi)\n",
    "    psi_deg = np.degrees(Y_psi)\n",
    "    \n",
    "    # Project ESM2 embeddings onto structural directions\n",
    "    helix_scores = X @ W_ss[list(ss_classes).index('H')] if 'H' in ss_classes else np.zeros(len(X))\n",
    "    sheet_scores = X @ W_ss[list(ss_classes).index('E')] if 'E' in ss_classes else np.zeros(len(X))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Traditional Ramachandran plot colored by secondary structure\n",
    "    for ss_type, color, label in [('H', 'red', 'Helix'), ('E', 'blue', 'Sheet'), ('-', 'gray', 'Coil')]:\n",
    "        mask = Y_ss == ss_type\n",
    "        if np.any(mask):\n",
    "            axes[0].scatter(phi_deg[mask], psi_deg[mask], c=color, alpha=0.6, s=1, label=label)\n",
    "    \n",
    "    axes[0].set_xlim(-180, 180)\n",
    "    axes[0].set_ylim(-180, 180)\n",
    "    axes[0].set_xlabel('Phi (degrees)')\n",
    "    axes[0].set_ylabel('Psi (degrees)')\n",
    "    axes[0].set_title('Traditional Ramachandran Plot')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ESM2 helix score projection\n",
    "    scatter = axes[1].scatter(phi_deg, psi_deg, c=helix_scores, cmap='Reds', s=1, alpha=0.7)\n",
    "    axes[1].set_xlim(-180, 180)\n",
    "    axes[1].set_ylim(-180, 180)\n",
    "    axes[1].set_xlabel('Phi (degrees)')\n",
    "    axes[1].set_ylabel('Psi (degrees)')\n",
    "    axes[1].set_title('ESM2 Helix Score Projection')\n",
    "    plt.colorbar(scatter, ax=axes[1])\n",
    "    \n",
    "    # ESM2 sheet score projection\n",
    "    scatter = axes[2].scatter(phi_deg, psi_deg, c=sheet_scores, cmap='Blues', s=1, alpha=0.7)\n",
    "    axes[2].set_xlim(-180, 180)\n",
    "    axes[2].set_ylim(-180, 180)\n",
    "    axes[2].set_xlabel('Phi (degrees)')\n",
    "    axes[2].set_ylabel('Psi (degrees)')\n",
    "    axes[2].set_title('ESM2 Sheet Score Projection')\n",
    "    plt.colorbar(scatter, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "ramachandran_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between biological properties\n",
    "def correlation_analysis():\n",
    "    \"\"\"Analyze correlations between different biological properties\"\"\"\n",
    "    \n",
    "    # Create property matrix\n",
    "    properties_matrix = np.column_stack([\n",
    "        Y_rsa,\n",
    "        Y_bfactors, \n",
    "        Y_contacts,\n",
    "        Y_hydrophobicity,\n",
    "        Y_charge,\n",
    "        np.degrees(Y_phi),\n",
    "        np.degrees(Y_psi)\n",
    "    ])\n",
    "    \n",
    "    property_names = ['RSA', 'B-factor', 'Contacts', 'Hydrophobicity', \n",
    "                     'Charge', 'Phi', 'Psi']\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(properties_matrix.T)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "                xticklabels=property_names, yticklabels=property_names)\n",
    "    plt.title('Correlation Between Biological Properties')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print interesting correlations\n",
    "    print(\"=== NOTABLE CORRELATIONS ===\")\n",
    "    for i in range(len(property_names)):\n",
    "        for j in range(i+1, len(property_names)):\n",
    "            corr = corr_matrix[i, j]\n",
    "            if abs(corr) > 0.3:\n",
    "                print(f\"{property_names[i]} vs {property_names[j]}: {corr:.3f}\")\n",
    "\n",
    "correlation_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e782f0",
   "metadata": {},
   "source": [
    "## Summary of Enhanced Interpretability Pipeline\n",
    "\n",
    "This enhanced pipeline now captures and analyzes multiple biological features:\n",
    "\n",
    "### **Structural Features**\n",
    "- **Secondary Structure**: Alpha-helix, beta-sheet, coil regions\n",
    "- **Backbone Geometry**: Phi/psi dihedral angles with Ramachandran analysis\n",
    "- **B-factors**: Atomic flexibility and thermal motion\n",
    "- **Contact Density**: Local packing environment\n",
    "\n",
    "### **Physicochemical Properties** \n",
    "- **Surface Accessibility**: Solvent exposure patterns\n",
    "- **Hydrophobicity**: Hydrophobic vs hydrophilic regions\n",
    "- **Electrostatic Charge**: Charged vs neutral residues\n",
    "\n",
    "### **Key Improvements**\n",
    "1. **Multi-target Learning**: Trained separate classifiers for each biological property\n",
    "2. **Cross-validation**: Robust performance estimates with 5-fold CV\n",
    "3. **Dimension Analysis**: Identified which ESM2 dimensions encode each property\n",
    "4. **Overlap Analysis**: Quantified sharing of dimensions between properties\n",
    "5. **Correlation Studies**: Explored relationships between biological features\n",
    "6. **Ramachandran Projections**: Connected sequence embeddings to 3D geometry\n",
    "\n",
    "### **Biological Insights**\n",
    "- ESM2 embeddings contain interpretable directions for multiple structural properties\n",
    "- Different biological features utilize both shared and distinct embedding dimensions\n",
    "- The model captures the relationship between sequence, structure, and dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
